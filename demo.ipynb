{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "tveJZTmZdq"
   },
   "source": [
    "# QCArchive+QCMLForge Demo with CyberShuttle\n",
    "\n",
    "The first half of this demo shows how to use QCArchive to setup a dataset\n",
    "and run computations with ease. The compute resource for this noteboook\n",
    "uses Cybershuttle; however, a purely local resource demo is available under\n",
    "`./demo_local.ipynb`.\n",
    "\n",
    "The second half of this demo shows how one can consume the generated data\n",
    "to train AP-Net models through QCMLForge. \n",
    "\n",
    "## How is this useful?\n",
    "Prior to using quantum mechanical (QM) methods for applications, often computational\n",
    "chemists will either consult previous studies of benchmarked methods on similar\n",
    "systems, or perform the benchmarking task themselves. Then after quantifying\n",
    "error, the level of theory that balances both expected error and is a reasonable\n",
    "computational cost will be selected for applying to novel system(s).\n",
    "\n",
    "The Sherrill research group has performed quite a few of these benchmarking\n",
    "studies particularly for studying intermolecular interaction energies. These\n",
    "interaction energies basically determine how attractive (or repulsive) molecules\n",
    "behave when brought close together. A more practical definition for an\n",
    "interaction energy (IE) is: \n",
    "\n",
    "$E_{\\rm IE} = E_{\\rm dimer} - E_{\\rm monomerA} - E_{\\rm monomerB}$.\n",
    "\n",
    "Hence, the interaction energy is defined as the energy difference between\n",
    "the dimer (when the two molecules are together) and the molecules on\n",
    "their own (monomerA and monomerB in isolation).\n",
    "\n",
    "To demonstrate how one might carryout the computational aspects of a\n",
    "benchmarking study, the present notebook will provide examples of managing\n",
    "datasets with QCArchive and running QM calculations prior to analyzing error\n",
    "statistics with respect to reference energies. The second half of the notebook\n",
    "provides examples on how you could then apply QM data towards training ML models\n",
    "through QCMLForge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jukit_cell_id": "FHk2C2mAci"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "Loaded airavata_jupyter_magic (2.1.3.post3) \n",
      "(current runtime = local)\n",
      "\n",
      "  %authenticate                              -- Authenticate to access high-performance runtimes.\n",
      "  %request_runtime <rt> [args]               -- Request a runtime named <rt> with configuration <args>.\n",
      "                                                Call multiple times to request multiple runtimes.\n",
      "  %restart_runtime <rt>                      -- Restart runtime <rt> if it hangs. This will clear all variables.\n",
      "  %stop_runtime <rt>                         -- Stop runtime <rt> when no longer needed.\n",
      "  %wait_for_runtime <rt>                     -- Wait for runtime <rt> to be ready.\n",
      "  %switch_runtime <rt>                       -- Switch the active runtime to <rt>. All subsequent cells will run here.\n",
      "  %%run_on <rt>                              -- Force a cell to always execute on <rt>, regardless of the active runtime.\n",
      "  %stat_runtime <rt>                         -- Show the status of runtime <rt>.\n",
      "  %copy_data source=<r1:f1> target=<r2:f2>   -- Copy <f1> in <r1> to <f2> in <r2>.\n",
      "  %open_tunnels <tn> --forward=<ports>       -- Open a TCP tunnel on the runtime.\n",
      "  %close_tunnels <tn>                        -- Close a TCP tunnel opened on the runtime.\n",
      "  %run_subprocess <pn> --command=<cmd>\n",
      "                       --forward=<ports>     -- Start a subprocess on the runtime.\n",
      "  %kill_subprocess <pn>                      -- Kill a subprocess started on the runtime.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU \"airavata-python-sdk[notebook]\"\n",
    "import airavata_jupyter_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jukit_cell_id": "VonilTFkTU"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Authenticated.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Authenticated.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%authenticate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jukit_cell_id": "1sXw3fhOc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting runtime=hpc_cpu...\n",
      "[NeuroData25VC1:cloud, 60 Minutes, 1 Node(s), 4 CPU(s), 0 GPU(s), 16000 MB RAM, 0 MB VRAM]\n",
      "* modules=[]\n",
      "* libraries=['numpy=2.2.5', 'pandas=2.2.3', 'pip', 'psycopg2=2.9.9', 'postgresql=17.4', 'pytest', 'python=3.10', 'psi4=1.9.1', 'pytorch-cpu=2.5.1', 'jupyter=1.1.1', 'requests', 'setuptools', 'torchaudio=2.5.1', 'torchvision=0.20.1', 'pytorch_geometric=2.6.1', 'pytorch_scatter=2.1.2=cpu*', 'pytorch-minimize=0.0.2', 'matplotlib=3.10.1', 'pydantic=1', 'scipy=1.15.*', 'tqdm']\n",
      "* pip=['cdsg-tools==0.0.2', 'qm-tools-aw==1.4.5', 'qcmlforge==0.0.8', 'qcfractal==0.59', 'qcmanybody', 'qcfractalcompute==0.59']\n",
      "* mounts=[]\n",
      "Requested runtime=hpc_cpu\n",
      "Request successful: runtime=hpc_cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c529238d5005405f92090b121ace116b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local:/tmp/connection_4trcoaz6.json --> hpc_cpu:connection_4trcoaz6.json... [200]\n",
      "started proc_name=hpc_cpu_kernel on rt=hpc_cpu. pid=3412\n",
      "forwarding ports=[20170, 20171, 20172, 20173, 20174]\n",
      "hpc_cpu:20170 -> access via 18.118.140.230:10005\n",
      "hpc_cpu:20171 -> access via 18.118.140.230:10006\n",
      "hpc_cpu:20172 -> access via 18.118.140.230:10007\n",
      "hpc_cpu:20173 -> access via 18.118.140.230:10008\n",
      "hpc_cpu:20174 -> access via 18.118.140.230:10009\n",
      "18.118.140.230\n",
      "started ipykernel client for hpc_cpu\n",
      "Remote Jupyter kernel launched and connected for runtime=hpc_cpu.\n",
      "Switched to runtime=hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "%request_runtime hpc_cpu --file=cybershuttle.yml --walltime=60 --use=NeuroData25VC1:cloud \n",
    "%wait_for_runtime hpc_cpu --live\n",
    "%switch_runtime hpc_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying local:combined_df_subset_358.pkl to hpc_cpu:combined_df_subset_358.pkl\n",
      "local:combined_df_subset_358.pkl --> hpc_cpu:combined_df_subset_358.pkl... [200]\n"
     ]
    }
   ],
   "source": [
    "%copy_data source=local:combined_df_subset_358.pkl target=hpc_cpu:combined_df_subset_358.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jukit_cell_id": "sb2BSlStsm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "Imports\n",
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "import psi4\n",
    "from pprint import pprint as pp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from qm_tools_aw import tools\n",
    "import matplotlib.pyplot as plt\n",
    "# QCElemental Imports\n",
    "from qcelemental.models import Molecule\n",
    "import qcelemental as qcel\n",
    "# Dataset Imports\n",
    "from qcportal import PortalClient\n",
    "from qcportal.singlepoint import SinglepointDatasetEntry, QCSpecification\n",
    "from qcportal.manybody import ManybodyDatasetEntry, ManybodySpecification\n",
    "from torch import manual_seed\n",
    "\n",
    "manual_seed(42)\n",
    "\n",
    "h2kcalmol = qcel.constants.hartree2kcalmol\n",
    "print('Imports')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "78H3oHPXBB"
   },
   "source": [
    "# QCArchive Setup\n",
    "QCArchive uses a PostgreSQL database for storing QM data including geometries,\n",
    "energies, and properties. Furthermore, to save on compute resources, every job\n",
    "generates a unique hash allowing future computations to be able to query previous\n",
    "job results for avoiding re-computing calculations, unless specifically requested.\n",
    "\n",
    "The following function initializes the QCArchive DB and QCFractal server, allowing\n",
    "us to then start the services for interfacing them through python. The configurations\n",
    "below will operate on a remote node through cybershuttle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jukit_cell_id": "BVc6W6uOta"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "/tmp/qcfractal\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Python executable:  /dev/shm/scratch/envs/9ff30a60/bin/python3.10\n",
      "QCFractal version:  0.59\n",
      "QCFractal alembic revision:  d5988aa750ae\n",
      "pg_ctl path:  /dev/shm/scratch/envs/9ff30a60/bin/pg_ctl\n",
      "PostgreSQL server version:  PostgreSQL 17.4 on x86_64-conda-linux-gnu, compiled by x86_64-conda-linux-gnu-cc (conda-forge gcc 13.3.0-2) 13.3.0, 64-bit\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Displaying QCFractal configuration below\n",
      "--------------------------------------------------------------------------------\n",
      "access_log_keep: 0\n",
      "allow_unauthenticated_read: true\n",
      "api:\n",
      "  extra_flask_options: null\n",
      "  extra_waitress_options: null\n",
      "  host: localhost\n",
      "  jwt_access_token_expires: 3600\n",
      "  jwt_refresh_token_expires: 86400\n",
      "  jwt_secret_key: nj3ZsNJk6V4WtMASCsjM6NDBgwNR4ddsJu4dg9wMgP4\n",
      "  num_threads_per_worker: 4\n",
      "  port: 7778\n",
      "  secret_key: 8pUrdqotCXzdxwXAG_EPu1fhn19KyMK1EMAcqJKG0UY\n",
      "  worker_timeout: 120\n",
      "api_limits:\n",
      "  add_molecules: 1000\n",
      "  add_records: 500\n",
      "  get_access_logs: 1000\n",
      "  get_dataset_entries: 2000\n",
      "  get_error_logs: 100\n",
      "  get_internal_jobs: 1000\n",
      "  get_managers: 1000\n",
      "  get_molecules: 1000\n",
      "  get_records: 1000\n",
      "  manager_tasks_claim: 200\n",
      "  manager_tasks_return: 10\n",
      "auto_reset:\n",
      "  compute_lost: 5\n",
      "  enabled: false\n",
      "  random_error: 5\n",
      "  unknown_error: 2\n",
      "base_folder: /tmp/qcfractal\n",
      "database:\n",
      "  base_folder: /tmp/qcfractal\n",
      "  data_directory: /tmp/qcfractal/postgres\n",
      "  database_name: qca\n",
      "  echo_sql: false\n",
      "  full_uri: null\n",
      "  host: localhost\n",
      "  logfile: /tmp/qcfractal/qcfractal_database.log\n",
      "  maintenance_db: postgres\n",
      "  own: true\n",
      "  password: Ss3kN4Bd0fzBnlEvTUoiz5_BcMYc9DKocrc99wVaxa8\n",
      "  pg_tool_dir: null\n",
      "  pool_size: 5\n",
      "  port: 5433\n",
      "  query: {}\n",
      "  username: qcfractal\n",
      "enable_security: false\n",
      "geoip2_dir: /tmp/qcfractal/geoip2\n",
      "geoip2_filename: GeoLite2-City.mmdb\n",
      "heartbeat_frequency: 60\n",
      "heartbeat_frequency_jitter: 0\n",
      "heartbeat_max_missed: 5\n",
      "hide_internal_errors: true\n",
      "homepage_directory: null\n",
      "homepage_redirect_url: null\n",
      "internal_job_keep: 0\n",
      "internal_job_processes: 1\n",
      "log_access: false\n",
      "logfile: null\n",
      "loglevel: INFO\n",
      "max_active_services: 20\n",
      "maxmind_license_key: null\n",
      "name: QCFractal Server\n",
      "s3:\n",
      "  access_key_id: null\n",
      "  bucket_map:\n",
      "    dataset_attachment: dataset_attachment\n",
      "  enabled: false\n",
      "  endpoint_url: null\n",
      "  passthrough: false\n",
      "  secret_access_key: null\n",
      "  verify: true\n",
      "service_frequency: 5\n",
      "strict_queue_tags: false\n",
      "temporary_dir: /home/exouser/cybershuttle/scratch/tmp\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "QCFractal setup complete\n",
      "To start the server run:\n",
      "  qcfractal-server --config=/tmp/qcfractal/qcfractal_config.yaml start\n",
      "To start the compute manager run:\n",
      "  qcfractal-compute-manager --config=/tmp/qcfractal/resources.yml\n",
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "from qcmlforge import qca\n",
    "import os\n",
    "\n",
    "# Update these if you request non-default resources from cybershuttle.yml\n",
    "max_workers = 3\n",
    "cores_per_worker = 8\n",
    "memory_per_worker = 12\n",
    "\n",
    "qca.setup_qcarchive_qcfractal(\n",
    "    #QCF_BASE_FOLDER=os.path.join(os.getcwd(), \"qcfractal\"),\n",
    "    QCF_BASE_FOLDER=os.path.join(\"/tmp\", \"qcfractal\"),\n",
    "    start=False,\n",
    "    reset=False,\n",
    "    db_config={\n",
    "        \"name\": None,\n",
    "        \"enable_security\": \"false\",\n",
    "        \"allow_unauthenticated_read\": None,\n",
    "        \"logfile\": None,\n",
    "        \"loglevel\": None,\n",
    "        \"service_frequency\": 5,\n",
    "        \"max_active_services\": None,\n",
    "        \"heartbeat_frequency\": 60,\n",
    "        \"log_access\": None,\n",
    "        \"database\": {\n",
    "            \"base_folder\": None,\n",
    "            \"host\": None,\n",
    "            \"port\": 5433,\n",
    "            \"database_name\": \"qca\",\n",
    "            \"username\": None,\n",
    "            \"password\": None,\n",
    "            \"own\": None,\n",
    "        },\n",
    "        \"api\": {\n",
    "            \"host\": None,\n",
    "            \"port\": 7778,\n",
    "            \"secret_key\": None,\n",
    "            \"jwt_secret_key\": None,\n",
    "        },\n",
    "    },\n",
    "    resources_config={\n",
    "            \"update_frequency\": 5,\n",
    "            \"cores_per_worker\": cores_per_worker,\n",
    "            \"max_workers\": max_workers,\n",
    "            \"memory_per_worker\": memory_per_worker,\n",
    "    },\n",
    "    conda_env=None,\n",
    "    worker_sh=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jukit_cell_id": "CwEhpqwLXX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "0\n",
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "get_ipython().system = os.system\n",
    "! mkdir -p qcfractal\n",
    "#!qcfractal-server --config=`pwd`/qcfractal/qcfractal_config.yaml start > qcfractal/qcf_server.log &\n",
    "!qcfractal-server --config=/tmp/qcfractal/qcfractal_config.yaml start > qcfractal/qcf_server.log &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jukit_cell_id": "3HjtiyIuFg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "0\n",
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "!qcfractal-compute-manager --config=/tmp/qcfractal/resources.yml &\n",
    "#!qcfractal-compute-manager --config=`pwd`/qcfractal/resources.yml &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "PortalClient(server_name='QCFractal Server', address='http://localhost:7778/', username='None')\n",
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "# Establish client connection\n",
    "client = PortalClient(\"http://localhost:7778\", verify=False)\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "X31FadtbG5"
   },
   "source": [
    "# QCArchive single point example with Psi4\n",
    "\n",
    "QCArchive/QCFractal can be used to run several QM softwares, but the focus of\n",
    "the present notebook will highlight the popular, open-source Psi4 program. \n",
    "\n",
    "As a simple example, we can specify a water dimer geometry and then\n",
    "create a singlepoint energy entry into the database with the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jukit_cell_id": "hMCmRgdGJ4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "[2025-05-07 07:32:11 UTC]     INFO: qcfractalcompute.config: Reading configuration data from /tmp/qcfractal/resources.yml\n",
      "(InsertMetadata(error_description=None, errors=[], inserted_idx=[], existing_idx=[0]),\n",
      " [1])\n",
      "cell finished on hpc_cpu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/dev/shm/scratch/envs/9ff30a60/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/dev/shm/scratch/envs/9ff30a60/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/dev/shm/scratch/envs/9ff30a60/lib/python3.10/site-packages/qcfractal/flask_app/waitress_app.py\", line 40, in run\n",
      "    serve(\n",
      "  File \"/dev/shm/scratch/envs/9ff30a60/lib/python3.10/site-packages/waitress/__init__.py\", line 13, in serve\n",
      "    server = _server(app, **kw)\n",
      "  File \"/dev/shm/scratch/envs/9ff30a60/lib/python3.10/site-packages/waitress/server.py\", line 78, in create_server\n",
      "    last_serv = TcpWSGIServer(\n",
      "  File \"/dev/shm/scratch/envs/9ff30a60/lib/python3.10/site-packages/waitress/server.py\", line 243, in __init__\n",
      "    self.bind_server_socket()\n",
      "  File \"/dev/shm/scratch/envs/9ff30a60/lib/python3.10/site-packages/waitress/server.py\", line 364, in bind_server_socket\n",
      "    self.bind(sockaddr)\n",
      "  File \"/dev/shm/scratch/envs/9ff30a60/lib/python3.10/site-packages/waitress/wasyncore.py\", line 374, in bind\n",
      "    return self.socket.bind(addr)\n",
      "OSError: [Errno 98] Address already in use\n"
     ]
    }
   ],
   "source": [
    "# Running a single job\n",
    "mol = Molecule.from_data(\n",
    "    \"\"\"\n",
    "     0 1\n",
    "     O  -1.551007  -0.114520   0.000000\n",
    "     H  -1.934259   0.762503   0.000000\n",
    "     H  -0.599677   0.040712   0.000000\n",
    "     --\n",
    "     0 1\n",
    "     O   1.350625   0.111469   0.000000\n",
    "     H   1.680398  -0.373741  -0.758561\n",
    "     H   1.680398  -0.373741   0.758561\n",
    "\n",
    "     units angstrom\n",
    "     no_reorient\n",
    "     symmetry c1\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "client.add_singlepoints(\n",
    "    [mol],\n",
    "    \"psi4\",\n",
    "    driver=\"energy\",\n",
    "    method=\"b3lyp\",\n",
    "    basis=\"aug-cc-pvdz\",\n",
    "    keywords={\"scf_type\": \"df\", \"e_convergence\": 6, \"freeze_core\": True},\n",
    "    tag=\"local\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "<bound method BaseModel.dict of SinglepointRecord(id=1, record_type='singlepoint', is_service=False, properties={'pe energy': 0.0, 'scf dipole': [1.01443376121478, 0.030397167953628346, 4.728134984227639e-12], 'calcinfo_nmo': 82, 'dft xc energy': -15.09393332583478, 'return_energy': -152.8965873433082, 'return_result': -152.8965873433082, 'scf_xc_energy': -15.09393332583478, 'calcinfo_natom': 6, 'calcinfo_nbeta': 10, 'current dipole': [1.01443376121478, 0.030397167953628346, 4.728134984227639e-12], 'current energy': -152.8965873433082, 'return_hessian': None, 'scf_iterations': 8, 'calcinfo_nalpha': 10, 'calcinfo_nbasis': 82, 'dft vv10 energy': 0.0, 'return_gradient': None, 'dft total energy': -152.89658734330817, 'scf_total_energy': -152.8965873433082, 'scf_dipole_moment': [1.01443376121478, 0.030397167953628346, 4.728134984227639e-12], 'scf_total_hessian': None, 'scf total energies': [-152.1832917902242, -152.54809853364753, -151.78477048281317, -152.8958414937561, -152.89589353340776, -152.8965718707635, -152.89658669740817, -152.8965873387496, -152.8965873433082], 'scf_total_gradient': None, 'dd solvation energy': 0.0, 'grid electrons beta': 10.000001013223184, 'one-electron energy': -282.4847235690834, 'two-electron energy': 108.01922155474664, 'grid electrons alpha': 10.000001013223184, 'grid electrons total': 20.000002026446367, 'scf iteration energy': -152.8965873433082, 'xc grid total points': 132401.0, 'xc grid radial points': 75.0, 'pcm polarization energy': 0.0, 'scf_one_electron_energy': -282.4847235690834, 'scf_two_electron_energy': 108.01922155474664, 'current reference energy': -152.8965873433082, 'nuclear_repulsion_energy': 36.66284799686338, 'xc grid spherical points': 302.0, 'dft functional total energy': -152.89658734330817}, extras={}, status=<RecordStatusEnum.complete: 'complete'>, manager_name='theoryfs-nsworkshopcpuvc1-compute-2.novalocal-d3f4a830-3afa-4f9e-966e-8ac6b3376f5f', created_on=datetime.datetime(2025, 5, 7, 7, 29, 15, 420281, tzinfo=datetime.timezone.utc), modified_on=datetime.datetime(2025, 5, 7, 7, 29, 22, 649203, tzinfo=datetime.timezone.utc), owner_user=None, owner_group=None, compute_history_=None, task_=None, service_=None, comments_=None, native_files_=None, specification=QCSpecification(program='psi4', driver=<SinglepointDriver.energy: 'energy'>, method='b3lyp', basis='aug-cc-pvdz', keywords={'scf_type': 'df', 'freeze_core': True, 'e_convergence': 6}, protocols=AtomicResultProtocols(wavefunction=<WavefunctionProtocolEnum.none: 'none'>, stdout=True, error_correction=ErrorCorrectionProtocol(default_policy=True, policies=None), native_files=<NativeFilesProtocolEnum.none: 'none'>)), molecule_id=1, molecule_=None, wavefunction_=None)>\n",
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "recs = client.query_records(\n",
    "    record_id=[1]\n",
    ")\n",
    "for rec in recs:\n",
    "    print(rec.dict)\n",
    "    #print(rec.properties['return_result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "6DmD5wp1nB"
   },
   "source": [
    "# Dataset Example\n",
    "While one could use the above logic for all calculations, QCArchive provides\n",
    "dataset options to make managing data for a specific application substantially\n",
    "easier. \n",
    "\n",
    "Prior to creating the QCArchive datasets, we will first load in data from a \n",
    "recently submitted Sherrill work [Levels of SAPT II](https://chemrxiv.org/engage/chemrxiv/article-details/67fe885f6e70d6fb2e033804). To faciliate insertion\n",
    "into the DB, we will create QCElemental Molecule objects in the pickle file\n",
    "and extract specific columns to store as variables for usage below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jukit_cell_id": "Z0wXrcgRq8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "     Benchmark SAPT2+3(CCD)DMP2 TOTAL ENERGY aqz  MP2 IE atz  \\\n",
      "0      -10.248                         -0.016681   -0.015629   \n",
      "1      -15.245                         -0.024763   -0.023012   \n",
      "2       -3.517                         -0.005637   -0.005608   \n",
      "3       -0.127                         -0.000187   -0.000194   \n",
      "4       -8.990                         -0.014655   -0.013687   \n",
      "..         ...                               ...         ...   \n",
      "353     -4.390                         -0.007196   -0.006835   \n",
      "354     -1.130                         -0.001489   -0.002395   \n",
      "355     -0.260                         -0.000432   -0.000450   \n",
      "356     -5.740                         -0.009198   -0.008974   \n",
      "357     -3.120                         -0.004909   -0.005518   \n",
      "\n",
      "     SAPT0 TOTAL ENERGY adz  \n",
      "0                 -0.018254  \n",
      "1                 -0.027620  \n",
      "2                 -0.005920  \n",
      "3                 -0.000192  \n",
      "4                 -0.016209  \n",
      "..                      ...  \n",
      "353               -0.008013  \n",
      "354               -0.002090  \n",
      "355               -0.000503  \n",
      "356               -0.009757  \n",
      "357               -0.005630  \n",
      "\n",
      "[358 rows x 4 columns]\n",
      "count    50.000000\n",
      "mean     12.080000\n",
      "std       2.739283\n",
      "min       4.000000\n",
      "25%      10.000000\n",
      "50%      12.000000\n",
      "75%      14.000000\n",
      "max      16.000000\n",
      "Name: size, dtype: float64\n",
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "# Creating a QCArchive Dataset...\n",
    "# Load in a dataset from a recent Sherrill work (Levels of SAPT II)\n",
    "df_LoS = pd.read_pickle(\"./combined_df_subset_358.pkl\")\n",
    "print(df_LoS[['Benchmark', 'SAPT2+3(CCD)DMP2 TOTAL ENERGY aqz', 'MP2 IE atz', 'SAPT0 TOTAL ENERGY adz' ]])\n",
    "\n",
    "# Limit to 100 molecules with maximum of 16 atoms to keep computational cost down\n",
    "df_LoS['size'] = df_LoS['atomic_numbers'].apply(lambda x: len(x))\n",
    "df_LoS = df_LoS[df_LoS['size'] <= 16]\n",
    "df_LoS = df_LoS.sample(50, random_state=42, axis=0).copy()\n",
    "# df_LoS = df_LoS.sample(50, random_state=42, axis=0).copy()\n",
    "df_LoS.reset_index(drop=True, inplace=True)\n",
    "print(df_LoS['size'].describe())\n",
    "\n",
    "# Create QCElemntal Molecules to generate the dataset\n",
    "def qcel_mols(row):\n",
    "    \"\"\"\n",
    "    Convert the row to a qcel molecule\n",
    "    \"\"\"\n",
    "    atomic_numbers = [row['atomic_numbers'][row['monAs']], row['atomic_numbers'][row['monBs']]]\n",
    "    coords = [row['coordinates'][row['monAs']], row['coordinates'][row['monBs']]]\n",
    "    cm = [\n",
    "        [row['monA_charge'], row['monA_multiplicity']],\n",
    "        [row['monB_charge'], row['monB_multiplicity']],\n",
    "     ]\n",
    "    return tools.convert_pos_carts_to_mol(atomic_numbers, coords, cm)\n",
    "df_LoS['qcel_molecule'] = df_LoS.apply(qcel_mols, axis=1)\n",
    "geoms = df_LoS['qcel_molecule'].tolist()\n",
    "ref_IEs = df_LoS['Benchmark'].tolist()\n",
    "sapt0_adz = (df_LoS['SAPT0 TOTAL ENERGY adz'] * h2kcalmol).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "iwmcvViziS"
   },
   "source": [
    "## Singlepoint Dataset\n",
    "\n",
    "First, to demonstrate how you could use this data for singlepoint energies/properties like the water\n",
    "dimer example above, we will create a singlepoint dataset and slot in our geometry data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jukit_cell_id": "i8ICwzPWaD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "Found LoS-singlepoint dataset, using this instead\n",
      "id=1 dataset_type='singlepoint' name='LoS-singlepoint' description='Dataset to contain LoS-singlepoint' tagline='' tags=[] group='default' visibility=True provenance={} default_tag='*' default_priority=<PriorityEnum.normal: 1> owner_user=None owner_group=None metadata={} extras={} contributed_values_=None attachments_=None auto_fetch_missing=True\n",
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "# Create client dataset\n",
    "ds_name = 'LoS-singlepoint'\n",
    "client_datasets = [i['dataset_name'] for i in client.list_datasets()]\n",
    "# Check if dataset already exists, if not create a new one\n",
    "if ds_name not in client_datasets:\n",
    "    ds = client.add_dataset(\"singlepoint\", ds_name,\n",
    "                            f\"Dataset to contain {ds_name}\")\n",
    "    print(f\"Added {ds_name} as dataset\")\n",
    "    # Insert entries into dataset\n",
    "    entry_list = []\n",
    "    for idx, mol in enumerate(geoms):\n",
    "        extras = {\n",
    "            \"name\": 'LoS-' + str(idx),\n",
    "            \"idx\": idx,\n",
    "        }\n",
    "        mol = Molecule.from_data(mol.dict(), extras=extras)\n",
    "        ent = SinglepointDatasetEntry(name=extras['name'], molecule=mol)\n",
    "        entry_list.append(ent)\n",
    "    ds.add_entries(entry_list)\n",
    "    print(f\"Added {len(entry_list)} molecules to dataset\")\n",
    "else:\n",
    "    ds = client.get_dataset(\"singlepoint\", ds_name)\n",
    "    print(f\"Found {ds_name} dataset, using this instead\")\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create QCSpecification and submit computations\n",
    "Now that the dataset has been created with our molecular systems, we will\n",
    "specify a level of theory (method/basis set) for running our calculations. We\n",
    "will name our specification \"psi4/SAPT0/cc-pvdz\" to easily label this\n",
    "specification's level of theory and program. This name will be used later\n",
    "during data collection and analysis. Although many QM methods that use a\n",
    "singlepoint energy would return a total energy, SAPT is a specialized method\n",
    "that directly computes the interaction energy between our monomers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jukit_cell_id": "vMkm00fo00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "InsertMetadata(error_description=None, errors=[], inserted_idx=[], existing_idx=[0])\n",
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "# SAPT0 Example\n",
    "method, basis = \"SAPT0\", \"cc-pvdz\"\n",
    "\n",
    "# Set the QCSpecification (QM interaction energy in our case)\n",
    "spec = QCSpecification(\n",
    "    program=\"psi4\",\n",
    "    driver=\"energy\",\n",
    "    method=method,\n",
    "    basis=basis,\n",
    "    keywords={\n",
    "        \"scf_type\": \"df\",\n",
    "    },\n",
    ")\n",
    "ds.add_specification(name=f\"psi4/{method}/{basis}\", specification=spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jukit_cell_id": "dwYb9dbQNI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "Submitted LoS-singlepoint dataset\n",
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "# Run the computations\n",
    "ds.submit()\n",
    "print(f\"Submitted {ds_name} dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jukit_cell_id": "2JMCNlehez"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "{'psi4/SAPT0/cc-pvdz': {<RecordStatusEnum.complete: 'complete'>: 50}}\n",
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "ds.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "kT14mJyNqJ"
   },
   "source": [
    "## Manybody Dataset - typical way to compute interaction energies with most QM methods\n",
    "\n",
    "While SAPT0 returns an interaction energy from a singlepoint energy, most other QM\n",
    "methods like HF, MP2, CCSD, or DFT would return a total dimer energy ($E_{\\rm dimer}$). To\n",
    "get QCArchive to run the energies of the dimer, monomerA, and monomerB and return the \n",
    "energy difference as above for $E_{\\rm IE}$, we can use the ManybodyDataset. The setup is\n",
    "similar to the singlepoint dataset above, but using different objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jukit_cell_id": "g31JlHrgso"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "Found LoS-manybody dataset, using this instead\n",
      "id=2 dataset_type='manybody' name='LoS-manybody' description='Dataset to contain LoS-manybody' tagline='' tags=[] group='default' visibility=True provenance={} default_tag='*' default_priority=<PriorityEnum.normal: 1> owner_user=None owner_group=None metadata={} extras={} contributed_values_=None attachments_=None auto_fetch_missing=True\n",
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "# Create client dataset\n",
    "ds_name_mb = 'LoS-manybody'\n",
    "client_datasets = [i['dataset_name'] for i in client.list_datasets()]\n",
    "# Check if dataset already exists, if not create a new one\n",
    "if ds_name_mb not in client_datasets:\n",
    "    print(\"Setting up new dataset:\", ds_name_mb)\n",
    "    ds_mb = client.add_dataset(\"manybody\", ds_name_mb,\n",
    "                            f\"Dataset to contain {ds_name_mb}\")\n",
    "    print(f\"Added {ds_name_mb} as dataset\")\n",
    "    # Insert entries into dataset\n",
    "    entry_list = []\n",
    "    for idx, mol in enumerate(geoms):\n",
    "        ent = ManybodyDatasetEntry(name=f\"LoS-IE-{idx}\", initial_molecule=mol)\n",
    "        entry_list.append(ent)\n",
    "    ds_mb.add_entries(entry_list)\n",
    "    print(f\"Added {len(entry_list)} molecules to dataset\")\n",
    "else:\n",
    "    ds_mb = client.get_dataset(\"manybody\", ds_name_mb)\n",
    "    print(f\"Found {ds_name_mb} dataset, using this instead\")\n",
    "\n",
    "print(ds_mb)\n",
    "\n",
    "# Can delete the dataset if you want to start over. Need to know dataset_id\n",
    "# client.delete_dataset(dataset_id=2, delete_records=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jukit_cell_id": "bYERcUudd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "{'psi4/hf/6-31g*': {<RecordStatusEnum.complete: 'complete'>: 1,\n",
      "  <RecordStatusEnum.running: 'running'>: 19,\n",
      "  <RecordStatusEnum.waiting: 'waiting'>: 30}}\n",
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "ds_mb.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify level of theory for Manybody dataset\n",
    "Similar to above, we can iterate through different levels of theory, create\n",
    "QCSpecifications, and submit the dataset computations. The major difference here\n",
    "is that now the \"levels\" must be specified for the ManybodySpecification. These\n",
    "\"levels\" refer to what level of theory and options we want to run our dimer (2)\n",
    "and monomer (1) computations with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jukit_cell_id": "gauw3VIjl9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "spec_mb program='qcmanybody' levels={1: QCSpecification(program='psi4', driver=<SinglepointDriver.energy: 'energy'>, method='hf', basis='6-31g*', keywords={'d_convergence': 8, 'scf_type': 'df'}, protocols=AtomicResultProtocols(wavefunction=<WavefunctionProtocolEnum.none: 'none'>, stdout=True, error_correction=ErrorCorrectionProtocol(default_policy=True, policies=None), native_files=<NativeFilesProtocolEnum.none: 'none'>)), 2: QCSpecification(program='psi4', driver=<SinglepointDriver.energy: 'energy'>, method='hf', basis='6-31g*', keywords={'d_convergence': 8, 'scf_type': 'df'}, protocols=AtomicResultProtocols(wavefunction=<WavefunctionProtocolEnum.none: 'none'>, stdout=True, error_correction=ErrorCorrectionProtocol(default_policy=True, policies=None), native_files=<NativeFilesProtocolEnum.none: 'none'>))} bsse_correction=[<BSSECorrectionEnum.cp: 'cp'>] keywords=ManybodyKeywords(return_total_data=False) protocols={}\n",
      "Submitted LoS-singlepoint dataset\n",
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "# Set multiple levels of theory - you can add/remove levels as you desire.\n",
    "# Computational scaling will get quite expensive with better methods and larger\n",
    "# basis sets\n",
    "\n",
    "methods = [\n",
    "    'hf', # 'svwn', # 'pbe', \n",
    "]\n",
    "basis_sets = [\n",
    "    '6-31g*'\n",
    "]\n",
    "\n",
    "for method in methods:\n",
    "    for basis in basis_sets:\n",
    "        # Set the QCSpecification (QM interaction energy in our case)\n",
    "        qc_spec_mb = QCSpecification(\n",
    "            program=\"psi4\",\n",
    "            driver=\"energy\",\n",
    "            method=method,\n",
    "            basis=basis,\n",
    "            keywords={\n",
    "                \"d_convergence\": 8,\n",
    "                \"scf_type\": \"df\",\n",
    "            },\n",
    "        )\n",
    "\n",
    "        spec_mb = ManybodySpecification(\n",
    "            program='qcmanybody',\n",
    "            bsse_correction=['cp'],\n",
    "            levels={\n",
    "                1: qc_spec_mb,\n",
    "                2: qc_spec_mb,\n",
    "            },\n",
    "        )\n",
    "        print(\"spec_mb\", spec_mb)\n",
    "\n",
    "        ds_mb.add_specification(name=f\"psi4/{method}/{basis}\", specification=spec_mb)\n",
    "\n",
    "        # Run the computations\n",
    "        ds_mb.submit()\n",
    "        print(f\"Submitted {ds_name} dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Status\n",
    "We can re-execute the following cell to see how many computations have completed and how many are running/waiting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jukit_cell_id": "qYukdPBXmi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "{'psi4/SAPT0/cc-pvdz': {<RecordStatusEnum.complete: 'complete'>: 50}}\n",
      "{'psi4/hf/6-31g*': {<RecordStatusEnum.complete: 'complete'>: 1,\n",
      "                    <RecordStatusEnum.running: 'running'>: 19,\n",
      "                    <RecordStatusEnum.waiting: 'waiting'>: 30}}\n",
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "pp(ds.status())\n",
    "pp(ds_mb.status())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAUSE HERE TO WAIT FOR COMPUTATIONS TO FINISH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "ds DONE\n",
      "ds_mb DONE\n",
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def wait_for_finish(tasks):\n",
    "    processing = True\n",
    "    while processing:\n",
    "        processing = False\n",
    "        for name, d in tasks.items():\n",
    "            for k, v in d.status().items():\n",
    "                if not all(i == \"complete\" for i in v.keys()):\n",
    "                    processing = True\n",
    "            print(name, \"RUNNING\" if processing else \"DONE\")\n",
    "        if processing:\n",
    "            time.sleep(15)\n",
    "\n",
    "wait_for_finish({\"ds\": ds, \"ds_mb\": ds_mb})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "xgdzc0Klhx"
   },
   "source": [
    "# Data Assembly\n",
    "\n",
    "NOTE: While you can execute the following blocks before all computations are\n",
    "complete, it is recommended to wait until all computations are complete to\n",
    "continue.\n",
    "\n",
    "QCArchive allows use to write functions that operate on each dataset entry to return exactly what information\n",
    "we want from every record through the `compile_values` method. The method returns a\n",
    "pandas dataframe containing our QCSpecification names and our specified columns for each entry \n",
    "in our assemble data functions. Here is the Singlepoint data assembly for SAPT calculations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "jukit_cell_id": "7RHL31QOoC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "[('psi4/SAPT0/cc-pvdz', 'qcel_molecule'),\n",
      " ('psi4/SAPT0/cc-pvdz', 'Z'),\n",
      " ('psi4/SAPT0/cc-pvdz', 'R'),\n",
      " ('psi4/SAPT0/cc-pvdz', 'TQ'),\n",
      " ('psi4/SAPT0/cc-pvdz', 'molecular_multiplicity'),\n",
      " ('psi4/SAPT0/cc-pvdz', 'SAPT Energies')]\n",
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "# Singlepoint data assemble\n",
    "def assemble_singlepoint_data(record):\n",
    "    record_dict = record.dict()\n",
    "    qcvars = record_dict[\"properties\"]\n",
    "    sapt_energies = np.array([np.nan, np.nan, np.nan, np.nan, np.nan])\n",
    "    sapt_energies[0] = qcvars['sapt total energy']\n",
    "    sapt_energies[1] = qcvars['sapt elst energy']\n",
    "    sapt_energies[2] = qcvars['sapt exch energy']\n",
    "    sapt_energies[3] = qcvars['sapt ind energy']\n",
    "    sapt_energies[4] = qcvars['sapt disp energy']\n",
    "    return (\n",
    "        record.molecule,\n",
    "        record.molecule.atomic_numbers,\n",
    "        record.molecule.geometry * qcel.constants.bohr2angstroms,\n",
    "        int(record.molecule.molecular_charge),\n",
    "        record.molecule.molecular_multiplicity,\n",
    "        sapt_energies,\n",
    "    )\n",
    "\n",
    "def assemble_singlepoint_data_value_names():\n",
    "    return [\n",
    "        'qcel_molecule',\n",
    "        \"Z\",\n",
    "        \"R\",\n",
    "        \"TQ\",\n",
    "        \"molecular_multiplicity\",\n",
    "        \"SAPT Energies\",\n",
    "    ]\n",
    "\n",
    "df = ds.compile_values(\n",
    "    value_call=assemble_singlepoint_data,\n",
    "    value_names=assemble_singlepoint_data_value_names(),\n",
    "    unpack=True,\n",
    ")\n",
    "pp(df.columns.tolist())\n",
    "df_sapt0 = df['psi4/SAPT0/cc-pvdz']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the assemble data function for our Manybody dataset results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "jukit_cell_id": "CDD1QjxHpc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "[('psi4/hf/6-31g*', 'qcel_molecule'),\n",
      " ('psi4/hf/6-31g*', 'CP_IE'),\n",
      " ('psi4/hf/6-31g*', 'NOCP_IE'),\n",
      " ('psi4/hf/6-31g*', 'Z'),\n",
      " ('psi4/hf/6-31g*', 'R'),\n",
      " ('psi4/hf/6-31g*', 'TQ'),\n",
      " ('psi4/hf/6-31g*', 'molecular_multiplicity')]\n",
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "def assemble_data(record):\n",
    "    record_dict = record.dict()\n",
    "    qcvars = record_dict[\"properties\"]\n",
    "    CP_IE = qcvars['results']['cp_corrected_interaction_energy'] * h2kcalmol\n",
    "    NOCP_IE = qcvars['results'].get('nocp_corrected_interaction_energy', np.nan) * h2kcalmol\n",
    "    return (\n",
    "    record.initial_molecule,\n",
    "    CP_IE,\n",
    "    NOCP_IE,\n",
    "    record.initial_molecule.atomic_numbers,\n",
    "    record.initial_molecule.geometry * qcel.constants.bohr2angstroms,\n",
    "    int(record.initial_molecule.molecular_charge),\n",
    "    record.initial_molecule.molecular_multiplicity,\n",
    "    )\n",
    "\n",
    "def assemble_data_value_names():\n",
    "    return [\n",
    "        'qcel_molecule',\n",
    "        \"CP_IE\",\n",
    "        \"NOCP_IE\",\n",
    "        \"Z\",\n",
    "        \"R\",\n",
    "        \"TQ\",\n",
    "        \"molecular_multiplicity\"\n",
    "    ]\n",
    "\n",
    "df_mb = ds_mb.compile_values(\n",
    "    value_call=assemble_data,\n",
    "    value_names=assemble_data_value_names(),\n",
    "    unpack=True,\n",
    ")\n",
    "\n",
    "pp(df_mb.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can pull together this data for analyzing our results. Our group has some\n",
    "common plotting scripts operating on pandas Dataframes, so we will convert\n",
    "our computed data into a format that is compatable with these scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "jukit_cell_id": "XT87RegBfm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)\n",
      "File \u001b[0;32m/dev/shm/scratch/envs/9ff30a60/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n",
      "\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\n",
      "\u001b[0;31mKeyError\u001b[0m: 'psi4/pbe/6-31g*'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[36], line 6\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcdsg_plot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m error_statistics\n",
      "\u001b[1;32m      3\u001b[0m df_sapt0[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msapt0 total energes\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_sapt0\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSAPT Energies\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m h2kcalmol, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;32m      4\u001b[0m df_plot \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n",
      "\u001b[1;32m      5\u001b[0m     {\n",
      "\u001b[0;32m----> 6\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqcel_molecule\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mdf_mb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpsi4/pbe/6-31g*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqcel_molecule\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n",
      "\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHF/6-31G*\u001b[39m\u001b[38;5;124m\"\u001b[39m: df_mb[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpsi4/hf/6-31g*\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCP_IE\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n",
      "\u001b[1;32m      8\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSAPT0/cc-pvdz\u001b[39m\u001b[38;5;124m'\u001b[39m: df_sapt0[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msapt0 total energes\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues,\n",
      "\u001b[1;32m      9\u001b[0m         \u001b[38;5;66;03m# \"svwn/6-31G*\": df_mb[\"psi4/svwn/6-31g*\"][\"CP_IE\"],\u001b[39;00m\n",
      "\u001b[1;32m     10\u001b[0m         \u001b[38;5;66;03m# \"PBE/6-31G*\": df_mb[\"psi4/pbe/6-31g*\"][\"CP_IE\"],\u001b[39;00m\n",
      "\u001b[1;32m     11\u001b[0m     }\n",
      "\u001b[1;32m     12\u001b[0m )\n",
      "\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# print(df_plot)\u001b[39;00m\n",
      "\u001b[1;32m     14\u001b[0m \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(i[\u001b[38;5;241m7\u001b[39m:]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m df_plot\u001b[38;5;241m.\u001b[39mindex]\n",
      "\n",
      "File \u001b[0;32m/dev/shm/scratch/envs/9ff30a60/lib/python3.10/site-packages/pandas/core/frame.py:4101\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n",
      "\u001b[1;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_single_key:\n",
      "\u001b[1;32m   4100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;32m-> 4101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_multilevel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   4102\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n",
      "\u001b[1;32m   4103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n",
      "\n",
      "File \u001b[0;32m/dev/shm/scratch/envs/9ff30a60/lib/python3.10/site-packages/pandas/core/frame.py:4159\u001b[0m, in \u001b[0;36mDataFrame._getitem_multilevel\u001b[0;34m(self, key)\u001b[0m\n",
      "\u001b[1;32m   4157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_getitem_multilevel\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n",
      "\u001b[1;32m   4158\u001b[0m     \u001b[38;5;66;03m# self.columns is a MultiIndex\u001b[39;00m\n",
      "\u001b[0;32m-> 4159\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   4160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, (\u001b[38;5;28mslice\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray)):\n",
      "\u001b[1;32m   4161\u001b[0m         new_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns[loc]\n",
      "\n",
      "File \u001b[0;32m/dev/shm/scratch/envs/9ff30a60/lib/python3.10/site-packages/pandas/core/indexes/multi.py:3040\u001b[0m, in \u001b[0;36mMultiIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n",
      "\u001b[1;32m   3037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mask\n",
      "\u001b[1;32m   3039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n",
      "\u001b[0;32m-> 3040\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_level_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   3041\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _maybe_to_slice(loc)\n",
      "\u001b[1;32m   3043\u001b[0m keylen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(key)\n",
      "\n",
      "File \u001b[0;32m/dev/shm/scratch/envs/9ff30a60/lib/python3.10/site-packages/pandas/core/indexes/multi.py:3391\u001b[0m, in \u001b[0;36mMultiIndex._get_level_indexer\u001b[0;34m(self, key, level, indexer)\u001b[0m\n",
      "\u001b[1;32m   3388\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mslice\u001b[39m(i, j, step)\n",
      "\u001b[1;32m   3390\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m-> 3391\u001b[0m     idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_loc_single_level_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlevel_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   3393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lexsort_depth \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;32m   3394\u001b[0m         \u001b[38;5;66;03m# Desired level is not sorted\u001b[39;00m\n",
      "\u001b[1;32m   3395\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mslice\u001b[39m):\n",
      "\u001b[1;32m   3396\u001b[0m             \u001b[38;5;66;03m# test_get_loc_partial_timestamp_multiindex\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m/dev/shm/scratch/envs/9ff30a60/lib/python3.10/site-packages/pandas/core/indexes/multi.py:2980\u001b[0m, in \u001b[0;36mMultiIndex._get_loc_single_level_index\u001b[0;34m(self, level_index, key)\u001b[0m\n",
      "\u001b[1;32m   2978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;32m   2979\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m-> 2980\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlevel_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m/dev/shm/scratch/envs/9ff30a60/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n",
      "\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n",
      "\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n",
      "\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n",
      "\u001b[1;32m   3810\u001b[0m     ):\n",
      "\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n",
      "\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n",
      "\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\n",
      "\u001b[0;31mKeyError\u001b[0m: 'psi4/pbe/6-31g*'\n",
      "cell finished on hpc_cpu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/exouser/cybershuttle/scratch/tmp/ipykernel_3414/139271986.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sapt0['sapt0 total energes'] = df_sapt0.apply(lambda x: x['SAPT Energies'][0] * h2kcalmol, axis=1)\n"
     ]
    }
   ],
   "source": [
    "from cdsg_plot import error_statistics\n",
    "\n",
    "df_sapt0['sapt0 total energes'] = df_sapt0.apply(lambda x: x['SAPT Energies'][0] * h2kcalmol, axis=1)\n",
    "df_plot = pd.DataFrame(\n",
    "    {\n",
    "        \"qcel_molecule\": df_mb[\"psi4/pbe/6-31g*\"][\"qcel_molecule\"],\n",
    "        \"HF/6-31G*\": df_mb[\"psi4/hf/6-31g*\"][\"CP_IE\"],\n",
    "        'SAPT0/cc-pvdz': df_sapt0['sapt0 total energes'].values,\n",
    "        # \"svwn/6-31G*\": df_mb[\"psi4/svwn/6-31g*\"][\"CP_IE\"],\n",
    "        # \"PBE/6-31G*\": df_mb[\"psi4/pbe/6-31g*\"][\"CP_IE\"],\n",
    "    }\n",
    ")\n",
    "# print(df_plot)\n",
    "id = [int(i[7:]) for i in df_plot.index]\n",
    "df_plot['id'] = id\n",
    "df_plot.sort_values(by='id', inplace=True, ascending=True)\n",
    "df_plot['reference'] = ref_IEs\n",
    "df_plot['SAPT0/aug-cc-pvdz'] = sapt0_adz\n",
    "df_plot['HF/6-31G* error'] = (df_plot['HF/6-31G*'] - df_plot['reference']).astype(float)\n",
    "# df_plot['PBE/6-31G* error'] = (df_plot['PBE/6-31G*'] - df_plot['reference']).astype(float)\n",
    "# df_plot['svwn/6-31G* error'] = (df_plot['svwn/6-31G*'] - df_plot['reference']).astype(float)\n",
    "df_plot['SAPT0/cc-pvdz error'] = (df_plot['SAPT0/cc-pvdz'] - df_plot['reference']).astype(float)\n",
    "df_plot['SAPT0/aug-cc-pvdz error'] = (df_plot['SAPT0/aug-cc-pvdz'] - df_plot['reference']).astype(float)\n",
    "# print(df_plot[['HF/6-31G*', 'SAPT0/cc-pvdz', 'reference', \"SAPT0/aug-cc-pvdz\"]])\n",
    "df_plot = df_plot.dropna(subset=['qcel_molecule', 'HF/6-31G*', 'SAPT0/cc-pvdz', 'SAPT0/aug-cc-pvdz'])\n",
    "print(df_plot[['HF/6-31G* error', 'SAPT0/cc-pvdz error', \"SAPT0/aug-cc-pvdz error\"]].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "6ziYQ8PdtF"
   },
   "source": [
    "# Plotting the interaction energy errors\n",
    "The function below will plot violin plots of the error distributions of the\n",
    "approximate level of theory and our reference. For this dataset, the reference\n",
    "energies are estimated CCSD(T)/CBS interaction energies provided by the Levels\n",
    "of SAPT II Supplemental Information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jukit_cell_id": "dRiuyCtOh1"
   },
   "outputs": [],
   "source": [
    "error_statistics.violin_plot(\n",
    "    df_plot,\n",
    "    df_labels_and_columns={\n",
    "        \"HF/6-31G*\": \"HF/6-31G* error\",\n",
    "        # \"svwn/6-31G*\": \"svwn/6-31G* error\",\n",
    "        # \"PBE/6-31G*\": \"PBE/6-31G* error\",\n",
    "        \"SAPT0/cc-pvdz\": \"SAPT0/cc-pvdz error\",\n",
    "        \"SAPT0/aug-cc-pvdz\": \"SAPT0/aug-cc-pvdz error\",\n",
    "    },\n",
    "    output_filename=\"S22-IE.png\",\n",
    "    figure_size=(6, 6),\n",
    "    x_label_fontsize=16,\n",
    "    ylim=(-15, 15),\n",
    "    rcParams={},\n",
    "    usetex=False,\n",
    "    ylabel=r\"IE Error vs. CCSD(T)/CBS (kcal/mol)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![S22-IE_violin.png](./S22-IE_violin.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "NoxyyvkpUK"
   },
   "source": [
    "# QCMLForge\n",
    "The previous sections conclude the benchmarking workflow; however, the remaining blocks in this\n",
    "notebook focus on using this QM data to train models and run inference to compare against QM methods. \n",
    "\n",
    "## Interaction energy ML model inference\n",
    "A specialized atom-pairwise neural network\n",
    "([AP-Net](https://pubs.rsc.org/en/content/articlehtml/2024/sc/d4sc01029a))\n",
    "architecture developed in the Sherrill group has been trained on 1.6 million\n",
    "dimers to predict SAPT0/aug-cc-pV(D+d)Z interaction energies. The model has been\n",
    "re-implemented and re-trained in PyTorch in QCMLForge for extending in the\n",
    "future. Below will take a pre-trained AP-Net2 model and predict energies on our\n",
    "current dimer dataset.  Note that the AP-Net2 architecture relies on first an\n",
    "AtomModel for predicting multipoles and intramolecular features, prior to more\n",
    "message passing neural networks for predicting SAPT component energies. As such,\n",
    "we must load pre-trained AtomModel weights and APNet2Model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jukit_cell_id": "8jtfD3m3S4"
   },
   "outputs": [],
   "source": [
    "import apnet_pt\n",
    "from apnet_pt.AtomPairwiseModels.apnet2 import APNet2Model\n",
    "from apnet_pt.AtomModels.ap2_atom_model import AtomModel\n",
    "\n",
    "atom_model = AtomModel().set_pretrained_model(model_id=0)\n",
    "ap2 = APNet2Model(atom_model=atom_model.model).set_pretrained_model(model_id=0)\n",
    "ap2.atom_model = atom_model.model\n",
    "print(df_plot['qcel_molecule'].tolist())\n",
    "apnet2_ies_predicted = ap2.predict_qcel_mols(\n",
    "    mols=df_plot['qcel_molecule'].tolist(),\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jukit_cell_id": "nxmLPrfAfx"
   },
   "outputs": [],
   "source": [
    "# AP-Net2 IE\n",
    "df_plot['APNet2'] = np.sum(apnet2_ies_predicted, axis=1)\n",
    "df_plot['APNet2 error'] = (df_plot['APNet2'] - df_plot['reference']).astype(float)\n",
    "#print(df_plot.sort_values(by='APNet2 error', ascending=True)[['APNet2', 'reference']])\n",
    "error_statistics.violin_plot(\n",
    "    df_plot,\n",
    "    df_labels_and_columns={\n",
    "        \"HF/6-31G*\": \"HF/6-31G* error\",\n",
    "        # \"svwn/6-31G*\": \"svwn/6-31G* error\",\n",
    "        # \"PBE/6-31G*\": \"PBE/6-31G* error\",\n",
    "        \"SAPT0/cc-pvdz\": \"SAPT0/cc-pvdz error\",\n",
    "        \"SAPT0/aug-cc-pvdz\": \"SAPT0/aug-cc-pvdz error\",\n",
    "        \"APNet2\": \"APNet2 error\",\n",
    "    },\n",
    "    output_filename=\"S22-IE-AP2.png\",\n",
    "    rcParams={},\n",
    "    usetex=False,\n",
    "    figure_size=(4, 4),\n",
    "    ylabel=r\"IE Error vs. CCSD(T)/CBS (kcal/mol)\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "To demonstrate transfer learning, we can use our reference data to then tune our\n",
    "pre-trained SAPT0 model to predict the CCSD(T)/CBS energies. Then we will\n",
    "re-plot, evaluating the model performance. Note that in any application, you\n",
    "should certainly use much more data and careful train/test set selection than\n",
    "what is done in this notebook. This is purely meant for demonstraion purposes\n",
    "only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jukit_cell_id": "XtMJQEokjd"
   },
   "outputs": [],
   "source": [
    "# Training models on new QM data: Transfer Learning\n",
    "\n",
    "from apnet_pt import pairwise_datasets\n",
    "\n",
    "ds2 = pairwise_datasets.apnet2_module_dataset(\n",
    "    root=\"data_dir\",\n",
    "    spec_type=None,\n",
    "    atom_model=atom_model,\n",
    "    qcel_molecules=df_plot['qcel_molecule'].tolist(),\n",
    "    energy_labels=[np.array([i]) for i in df_plot['reference'].tolist()],\n",
    "    skip_compile=True,\n",
    "    force_reprocess=True,\n",
    "    atomic_batch_size=8,\n",
    "    prebatched=False,\n",
    "    in_memory=True,\n",
    "    batch_size=4,\n",
    ")\n",
    "print(ds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jukit_cell_id": "xXslqNQSRI"
   },
   "outputs": [],
   "source": [
    "# Transfer Learning APNet2 model on computed QM data\n",
    "ap2.train(\n",
    "    dataset=ds2,\n",
    "    n_epochs=50,\n",
    "    transfer_learning=True,\n",
    "    skip_compile=True,\n",
    "    model_path=\"apnet2_transfer_learning.pt\",\n",
    "    split_percent=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jukit_cell_id": "KPOeFMBhWm"
   },
   "outputs": [],
   "source": [
    "# AP-Net2 IE\n",
    "apnet2_ies_predicted_transfer = ap2.predict_qcel_mols(\n",
    "    mols=df_plot['qcel_molecule'].tolist(),\n",
    "    batch_size=16,\n",
    ")\n",
    "df_plot['APNet2 transfer'] = np.sum(apnet2_ies_predicted_transfer, axis=1)\n",
    "df_plot['APNet2 transfer error'] = (df_plot['APNet2 transfer'] - df_plot['reference']).astype(float)\n",
    "\n",
    "error_statistics.violin_plot(\n",
    "    df_plot,\n",
    "    df_labels_and_columns={\n",
    "        \"HF/6-31G*\": \"HF/6-31G* error\",\n",
    "        # \"svwn/6-31G*\": \"svwn/6-31G* error\",\n",
    "        # \"PBE/6-31G*\": \"PBE/6-31G* error\",\n",
    "        \"SAPT0/aug-cc-pvdz\": \"SAPT0/aug-cc-pvdz error\",\n",
    "        \"APNet2\": \"APNet2 error\",\n",
    "        \"APNet2 transfer\": \"APNet2 transfer error\",\n",
    "    },\n",
    "    output_filename=\"S22-IE-AP2-tf.png\",\n",
    "    rcParams={},\n",
    "    usetex=False,\n",
    "    figure_size=(6, 4),\n",
    "    ylabel=r\"IE Error vs. CCSD(T)/CBS (kcal/mol)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "M3Q6tUC2AJ"
   },
   "source": [
    "## $\\Delta$ Models\n",
    "Another option available in QCMLForge is to train $\\Delta {\\rm APNet2}$ models \n",
    "to predict the difference between one level of theory and another. This\n",
    "example highlights learning how to go from our computed HF/6-31G* IEs\n",
    "to our CCSD(T)/CBS energies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jukit_cell_id": "ROLVxSHnj2"
   },
   "outputs": [],
   "source": [
    "from apnet_pt.pt_datasets.dapnet_ds import dapnet2_module_dataset_apnetStored\n",
    "\n",
    "delta_energies = df_plot['HF/6-31G* error'].tolist()\n",
    "\n",
    "# Only operates in pre-batched mode\n",
    "ds_dap2 = dapnet2_module_dataset_apnetStored(\n",
    "    root=\"data_dir\",\n",
    "    r_cut=5.0,\n",
    "    r_cut_im=8.0,\n",
    "    spec_type=None,\n",
    "    max_size=None,\n",
    "    force_reprocess=True,\n",
    "    batch_size=2,\n",
    "    num_devices=1,\n",
    "    skip_processed=False,\n",
    "    skip_compile=True,\n",
    "    print_level=2,\n",
    "    in_memory=True,\n",
    "    m1=\"HF/6-31G*\",\n",
    "    m2=\"CCSD(T)/CBS\",\n",
    "    qcel_molecules=df_plot['qcel_molecule'].tolist(),\n",
    "    energy_labels=delta_energies,\n",
    ")\n",
    "print(ds_dap2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jukit_cell_id": "jfEVLnbL5w"
   },
   "outputs": [],
   "source": [
    "from apnet_pt.AtomPairwiseModels.dapnet2 import dAPNet2Model\n",
    "\n",
    "dap2 = dAPNet2Model(\n",
    "    atom_model=AtomModel().set_pretrained_model(model_id=0),\n",
    "    apnet2_model=APNet2Model().set_pretrained_model(model_id=0).set_return_hidden_states(True),\n",
    ")\n",
    "dap2.train(\n",
    "    ds_dap2,\n",
    "    n_epochs=50,\n",
    "    skip_compile=True,\n",
    "    split_percent=0.6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jukit_cell_id": "BbSVmmebsN"
   },
   "outputs": [],
   "source": [
    "dAPNet2_ies_predicted_transfer = dap2.predict_qcel_mols(\n",
    "    mols=df_plot['qcel_molecule'].tolist(),\n",
    "    batch_size=2,\n",
    ")\n",
    "df_plot['dAPNet2'] = dAPNet2_ies_predicted_transfer\n",
    "df_plot['HF/6-31G*-dAPNet2'] = df_plot['HF/6-31G*'] - df_plot['dAPNet2']\n",
    "print(df_plot[['dAPNet2', 'HF/6-31G*', 'HF/6-31G*-dAPNet2',  'reference']])\n",
    "df_plot['dAPNet2 error'] = (df_plot['HF/6-31G*-dAPNet2'] - df_plot['reference']).astype(float)\n",
    "\n",
    "error_statistics.violin_plot(\n",
    "    df_plot,\n",
    "    df_labels_and_columns={\n",
    "        \"HF/6-31G*\": \"HF/6-31G* error\",\n",
    "        # \"svwn/6-31G*\": \"svwn/6-31G* error\",\n",
    "        # \"PBE/6-31G*\": \"PBE/6-31G* error\",\n",
    "        \"SAPT0/aug-cc-pvdz\": \"SAPT0/aug-cc-pvdz error\",\n",
    "        \"APNet2\": \"APNet2 error\",\n",
    "        \"APNet2 transfer\": \"APNet2 transfer error\",\n",
    "        \"dAPNet2 HF/6-31G* to CCSD(T)/CBS\": \"dAPNet2 error\",\n",
    "    },\n",
    "    output_filename=\"S22-IE-AP2-dAP2.png\",\n",
    "    rcParams={},\n",
    "    usetex=False,\n",
    "    figure_size=(6, 4),\n",
    "    ylabel=r\"IE Error vs. CCSD(T)/CBS (kcal/mol)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jukit_cell_id": "OVVcYRXWUA"
   },
   "outputs": [],
   "source": [
    "%stop_runtime hpc_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "H2TTLmA061"
   },
   "source": [
    "# The end...\n",
    "\n",
    "This notebook has been designed to help demonstrate how QCArchive can be used to\n",
    "compute QM properties through cybershuttle, and then leverage that data for\n",
    "analysis or training AP-Net based models through QCMLForge. \n",
    "\n",
    "If you have any questions about this notebook or used packages, please feel\n",
    "free to reach out to me at awallace43@gatech.edu!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
